{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a4e59b5-6416-4233-8c49-867c1d9b9d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import logging\n",
    "import os\n",
    "import ta\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "wd = os.path.abspath(\"__file__\").replace(\"/__file__\", \"\").replace(\"notebooks\", \"\")\n",
    "os.chdir(wd)\n",
    "\n",
    "from datetime import datetime, timedelta, date\n",
    "from logging.handlers import TimedRotatingFileHandler\n",
    "from src.utils import get_jinja_yaml_conf, create_db_engine, Clickhouse_client, Postgres_connect\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "today = datetime.now().date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fc5b1cd-2170-4f96-8e51-0ee4d703f584",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = get_jinja_yaml_conf('./conf/logging.yml', './conf/data.yml')\n",
    "tqdm.pandas()\n",
    "\n",
    "# logger 설정\n",
    "stream = logging.StreamHandler()\n",
    "# stream.setLevel(logging.DEBUG)\n",
    "logger = logging.getLogger('main')\n",
    "logging.basicConfig(level=eval(conf['logging']['level']),\n",
    "    format=conf['logging']['format'],\n",
    "    handlers = [TimedRotatingFileHandler(filename =  conf['logging']['file_name'],\n",
    "                                when=conf['logging']['when'],\n",
    "                                interval=conf['logging']['interval'],\n",
    "                                backupCount=conf['logging']['backupCount']), \n",
    "                                   stream]\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1cd985e-adbd-48a2-9bf5-2a7b81b8ca56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only for notebooks\n",
    "import re\n",
    "\n",
    "os.environ['_ts'] = datetime.astimezone(datetime.now()).strftime('%Y-%m-%d %H:%M:%S %z')\n",
    "\n",
    "with open('./conf/credentials', \"r\") as file:\n",
    "    # 각 라인 읽기\n",
    "    for line in file:\n",
    "        # 주석(#) 또는 빈 줄은 무시\n",
    "        if line.strip() == '' or line.startswith('#'):\n",
    "            continue\n",
    "\n",
    "        # 각 라인을 '='를 기준으로 key와 value로 분리\n",
    "        key, value = line.strip().split('=', 1)\n",
    "\n",
    "        # $ENV 형식의 환경변수가 있을 경우 해당 값을 가져와서 설정\n",
    "        env_var_pattern = re.compile(r'\\$(\\w+)')\n",
    "        matches = env_var_pattern.findall(value)\n",
    "        for match in matches:\n",
    "            value = value.replace(f\"${match}\", os.environ.get(match, \"\")).replace('\"', '')\n",
    "\n",
    "        # 환경변수로 설정\n",
    "        os.environ[key] = value\n",
    "\n",
    "os.environ['full_save'] = 'false'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c28af2f2-4ddc-46ad-85e3-8dbdd3dc37f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-27 09:27:12,207 (utils.py 60) INFO ::: Connect to 172.20.10.3. DB_NAME is stocks\n",
      "2024-08-27 09:27:12,212 (utils.py 396) INFO ::: sql execute: SELECT COUNT(*) FROM stocks.daily_stock FINAL\n"
     ]
    }
   ],
   "source": [
    "# DB 설정\n",
    "engine = create_db_engine(os.environ)\n",
    "postgres_conn = Postgres_connect(engine)\n",
    "click_conn = Clickhouse_client(user_name = os.environ['CLICK_USER'], password = os.environ['CLICK_PW'])\n",
    "full_save = True if click_conn.get_count('stocks', 'daily_stock') == 0 else os.environ['full_save'].lower() == 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2df98e2-ea9e-4040-aa46-c34f54cf15b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-27 09:27:12,410 (utils.py 396) INFO ::: sql execute: SELECT `기준일자`, `지수명`, `시가총액`, `거래대금`, `수익률`, `수익률5일`, `수익률20일`, `수익률60일`, `수익률120일`, `수익률240일`, `수익률720일` FROM stocks.daily_market FINAL WHERE `지수명` IN ('코스피', '코스닥')ORDER BY `기준일자`, `계열구분`, `지수명`\n",
      "2024-08-27 09:27:12,535 (utils.py 284) INFO ::: data processing is started!\n",
      "2024-08-27 09:27:12,535 (utils.py 396) INFO ::: sql execute: DESCRIBE TABLE stocks.daily_market\n",
      "2024-08-27 09:27:12,569 (utils.py 396) INFO ::: sql execute: SELECT sorting_key FROM system.tables WHERE name = 'daily_market' AND database = 'stocks'\n",
      "2024-08-27 09:27:12,571 (utils.py 305) INFO ::: data processing is finished.\n",
      "2024-08-27 09:27:12,575 (utils.py 396) INFO ::: sql execute: SELECT MAX(`기준일자`) \n",
      "                                FROM stocks.daily_stock \n"
     ]
    }
   ],
   "source": [
    "# 마켓 지표 가져오기\n",
    "return_cols = ['수익률'] + [f'수익률{day}일' for day in conf['agg_days']]\n",
    "market_indicator = click_conn.get_table('stocks', 'daily_market', \n",
    "                            columns = ['기준일자', '지수명', '시가총액', '거래대금'] + return_cols,\n",
    "                              where = [\"`지수명` IN ('코스피', '코스닥')\"],\n",
    "                              orderby_cols = ['기준일자', '계열구분', '지수명']\n",
    "                                       ).rename(columns = {col: f'시장{col}' for col in return_cols}).rename(columns = {'지수명': '시장구분', '시가총액': '시장시가총액', '거래대금': '시장거래대금'})\n",
    "\n",
    "market_indicator['기준일자'] = market_indicator['기준일자'].dt.date\n",
    "market_indicator['시장구분'] = market_indicator['시장구분'].map(lambda x: 'KOSPI' if x == '코스피' else 'KOSDAQ')\n",
    "\n",
    "market_dates = market_indicator['기준일자'].sort_values().unique()\n",
    "\n",
    "# 처리할 날짜 설정\n",
    "latest_stock_date = pd.to_datetime(\n",
    "                        click_conn.get_maxmin_col(conf['daily_stock']['database'], conf['daily_stock']['table'], \n",
    "                            column = '기준일자', is_min = False)[0]\n",
    "    ).date()\n",
    "\n",
    "\n",
    "upload_date = market_dates[0] if full_save else latest_stock_date + timedelta(days = 1)\n",
    "# if upload_date > market_dates[-1]:\n",
    "#     logger.info(\"Latest stock information is uploaded already.\")\n",
    "#     return \n",
    "\n",
    "start_idx = np.where(market_dates >= upload_date)[0][0] - max(conf['agg_days'])\n",
    "# start_idx = len(market_dates) - max(conf['agg_days']) - 1\n",
    "start_date = market_dates[0] if start_idx < 0 else market_dates[start_idx] \n",
    "end_date = market_dates[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30928733-c9b1-4305-8068-69654624966c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 회사/주가정보 가져오기\n",
    "stock_info = postgres_conn.get_data(conf['sto_info']['database'], conf['sto_info']['table'], \n",
    "                      columns = conf['sto_info']['columns'],\n",
    "                      where = [\n",
    "                              \"증권구분 = '주권'\", \n",
    "                               \"주식종류 = '보통주'\", \n",
    "                               \"액면가 != '무액면'\",\n",
    "                               \"시장구분 IN ('KOSPI', 'KOSDAQ')\",\n",
    "                               f\"상장일 <= '{end_date}'\",\n",
    "                              f\"기준일자 >= '{start_date}'\"],\n",
    "                        orderby_cols = ['기준일자'])\n",
    "\n",
    "stock_price = postgres_conn.get_data(conf['sto_stocks']['database'], conf['sto_stocks']['table'], \n",
    "                      columns = conf['sto_stocks']['columns'],\n",
    "                      where = [f\"종목코드 IN ('{\"','\".join(stock_info['종목코드'].unique())}')\",\n",
    "                              f\"기준일자 <= '{end_date}'\",\n",
    "                              f\"기준일자 >= '{start_date}'\"])\n",
    "\n",
    "stock_price['시총순위'] = stock_price.groupby('기준일자')['시가총액'].rank()\n",
    "stock_price['시총순위백분율'] = stock_price.groupby('기준일자')['시가총액'].rank(pct = True)\n",
    "stock_price['거래대금순위'] = stock_price.groupby('기준일자')['거래대금'].rank()\n",
    "stock_price['거래대금순위백분율'] = stock_price.groupby('기준일자')['거래대금'].rank(pct = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f3cd67-97a8-48e6-a51b-612aa8400f97",
   "metadata": {},
   "source": [
    "### full_save 관련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fb4aeb4-6af8-4e0e-a30b-561e064732a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-27 09:27:32,597 (utils.py 396) INFO ::: sql execute: SELECT `종목코드`, `수정액면가` FROM stocks.daily_stock FINAL ORDER BY `기준일자` DESC LIMIT 1 BY `종목코드`\n",
      "2024-08-27 09:27:32,863 (utils.py 284) INFO ::: data processing is started!\n",
      "2024-08-27 09:27:32,863 (utils.py 396) INFO ::: sql execute: DESCRIBE TABLE stocks.daily_stock\n",
      "2024-08-27 09:27:32,870 (utils.py 396) INFO ::: sql execute: SELECT sorting_key FROM system.tables WHERE name = 'daily_stock' AND database = 'stocks'\n",
      "2024-08-27 09:27:32,872 (utils.py 305) INFO ::: data processing is finished.\n",
      "2024-08-27 09:27:33,543 (utils.py 396) INFO ::: sql execute: SELECT `기준일자`, `종목코드`, `시총순위`, `시총순위백분율`, `거래대금순위`, `거래대금순위백분율` FROM stocks.daily_stock FINAL WHERE RIGHT(`종목코드`, 6) IN \n",
      "                            ('456070')\n",
      "                             AND `기준일자` < '2024-08-23'\n",
      "2024-08-27 09:27:33,671 (utils.py 362) WARNING ::: There are no data that fulfill condition.\n",
      "/tmp/ipykernel_431/478800222.py:45: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  stock_price = pd.concat([stock_price, full_stock_price]).drop_duplicates(keep = 'last')\n"
     ]
    }
   ],
   "source": [
    "# full_save = False일 때\n",
    "if not full_save:\n",
    "    face_value_history = click_conn.get_table(conf['daily_stock']['database'], conf['daily_stock']['table'],\n",
    "                                            columns = ['종목코드', '수정액면가'],\n",
    "                                            orderby_cols = ['기준일자 DESC'],\n",
    "                                            post_sql = ' LIMIT 1 BY `종목코드`')\n",
    "    \n",
    "    last_face_value = stock_info.drop_duplicates('종목코드', keep = 'last')[['종목코드', '액면가']]\n",
    "    face_value_history['종목코드'] = face_value_history['종목코드'].map(lambda x: x[1:])\n",
    "    merge_face_value = last_face_value.merge(face_value_history, how = 'left').astype({'액면가': 'Int64', '수정액면가': 'Int64'})\n",
    "    full_save_idx = (merge_face_value['액면가'] != merge_face_value['수정액면가']) | (merge_face_value['수정액면가'].isnull())\n",
    "    full_save_stocks = merge_face_value.loc[full_save_idx, '종목코드'].tolist()\n",
    "    \"\"\"\n",
    "    full_save가 필요한 주식 조건\n",
    "    1. 업로드 대상 테이블에 주가 정보가 없을 때\n",
    "    2. 주식의 최근 액면가가 변경됐을 때\n",
    "    \"\"\" \n",
    "    if len(full_save_stocks) > 0:\n",
    "        stock_clause = f\"\"\"\n",
    "                            ('{\"', '\".join([code for code in full_save_stocks])}')\n",
    "                            \"\"\"\n",
    "        \n",
    "        full_stock_info = postgres_conn.get_data(conf['sto_info']['database'], conf['sto_info']['table'], \n",
    "                          columns = conf['sto_info']['columns'],\n",
    "                          where = [\"증권구분 = '주권'\", \n",
    "                                   \"주식종류 = '보통주'\", \n",
    "                                   \"액면가 != '무액면'\",\n",
    "                                   \"시장구분 IN ('KOSPI', 'KOSDAQ')\",\n",
    "                                  f\"단축코드 IN {stock_clause}\"],\n",
    "                            orderby_cols = ['기준일자'])\n",
    "    \n",
    "        full_stock_price = postgres_conn.get_data(conf['sto_stocks']['database'], conf['sto_stocks']['table'], \n",
    "                          columns = conf['sto_stocks']['columns'],\n",
    "                          where = [f\"종목코드 IN {stock_clause}\",\n",
    "                                  f\"기준일자 < '{upload_date}'\"])\n",
    "\n",
    "        full_stock_history = click_conn.get_table(conf['daily_stock']['database'], conf['daily_stock']['table'],\n",
    "                    columns = ['기준일자', '종목코드', '시총순위', '시총순위백분율', '거래대금순위', '거래대금순위백분율'],\n",
    "                    where = [f\"RIGHT(`종목코드`, 6) IN {stock_clause}\",\n",
    "                            f\"`기준일자` < '{upload_date}'\"])\n",
    "\n",
    "        full_stock_price = full_stock_price.merge(full_stock_history, how = 'inner')\n",
    "    \n",
    "        stock_info = pd.concat([stock_info, full_stock_info]).drop_duplicates(keep = 'last')\n",
    "        stock_price = pd.concat([stock_price, full_stock_price]).drop_duplicates(keep = 'last')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88bca3e9-b0c3-4685-b836-ea567a69c085",
   "metadata": {},
   "source": [
    "# Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01db77aa-b2e2-4876-8fac-5a14d170f85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 회사/주가 정보 합치기\n",
    "merge_info = market_indicator.merge(stock_info, on = ['기준일자', '시장구분'], how = 'inner')\n",
    "merge_info = merge_info.merge(stock_price, on = ['기준일자', '종목코드'], how = 'left').rename(columns={'등락률': '수익률', '대비': '전일대비'})\n",
    "merge_info.sort_values(['종목코드', '기준일자'], inplace = True)\n",
    "merge_info = merge_info.merge(merge_info.groupby('종목코드')['액면가'].last().reset_index().rename(columns = {'액면가': '수정액면가'}), on = '종목코드', how = 'left')\n",
    "\n",
    "# 전체 시장 정보\n",
    "total_mkt_amount = market_indicator.groupby('기준일자')[['시장시가총액', '시장거래대금']].sum().rename(columns = {'시장시가총액': '전체시가총액', '시장거래대금': '전체거래대금'}).reset_index()\n",
    "merge_info = merge_info.merge(total_mkt_amount, how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea4405dd-e328-49fa-9294-f69ec0cee164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최근 회사 액면가에 맞춰 수정칼럼 추가\n",
    "val_chg =  merge_info['수정액면가'].astype('Int64') / merge_info['액면가'].astype('Int64')\n",
    "merge_info['수정시가'] = merge_info['시가'] * val_chg\n",
    "merge_info['수정고가'] = merge_info['고가'] * val_chg\n",
    "merge_info['수정저가'] = merge_info['저가'] * val_chg\n",
    "merge_info['수정종가'] = merge_info['종가'] * val_chg\n",
    "merge_info['수정전일대비'] = merge_info['전일대비'] * val_chg\n",
    "merge_info['수정거래량'] = merge_info['거래량'] / val_chg\n",
    "merge_info['수정상장주식수'] = merge_info['상장주식수'] / val_chg\n",
    "merge_info[\"시장대비_수익률\"] = merge_info[\"수익률\"] - merge_info[\"시장수익률\"]\n",
    "merge_info[\"거래대금시장시총비율\"] = merge_info[\"거래대금\"] / merge_info[\"시장시가총액\"] * 100\n",
    "merge_info[\"거래대금시장거래대금비율\"] = merge_info[\"거래대금\"] / merge_info[\"시장거래대금\"] * 100\n",
    "merge_info[\"거래대금전체시총비율\"] = merge_info[\"거래대금\"] / merge_info[\"전체시가총액\"] * 100\n",
    "merge_info[\"거래대금전체거래대금비율\"] = merge_info[\"거래대금\"] / merge_info[\"전체거래대금\"] * 100\n",
    "merge_info['상장경과일'] = merge_info['상장일'].map(lambda x: (today - x).days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "632e51cc-c85b-4b6b-99ab-32952d13a421",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-27 09:31:34,700 (975709587.py 4) INFO ::: aggregating process of 5days starts!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20f2d1b470c446169956ccc699eedecc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-27 09:31:43,748 (975709587.py 4) INFO ::: aggregating process of 20days starts!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f979692be144408c86e7c749f693f609",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-27 09:31:52,291 (975709587.py 4) INFO ::: aggregating process of 60days starts!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7de3c98a78bf4a7698f2a141c261a4c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-27 09:32:00,474 (975709587.py 4) INFO ::: aggregating process of 120days starts!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acb7958aa9c342a49b42e767b83bec87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-27 09:32:08,528 (975709587.py 4) INFO ::: aggregating process of 240days starts!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b70816568ad84f18a0bcf5cc7a4e0e0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-27 09:32:15,832 (975709587.py 4) INFO ::: aggregating process of 720days starts!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e84d97b0163d4057a79b457bd2168b87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "904ce502bc03408b9eab6c63d2b2ac88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2667 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d0c588a5c67476c815c75e32d0d242d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2667 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e863e4a97024b2289febf778b9436ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2667 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0390702a7724465991b4ff125f41d49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2667 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b64e3e6f7c9542f2b9dce3c501a72c54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2667 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_431/975709587.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merge_info['mavg'] = group_info.progress_apply(lambda x: ta.volatility.bollinger_mavg(close = x['수정종가'], window = 20)).reset_index(level = 0).iloc[:, -1]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55f4ac32498d42e4bcddae189d64783b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2667 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_431/975709587.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merge_info['up'] = group_info.progress_apply(lambda x: ta.volatility.bollinger_hband(close = x['수정종가'], window = 20, window_dev = 2)).reset_index(level = 0).iloc[:, -1]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ffcae05f4dc4348bbb51e4dedca97cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2667 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_431/975709587.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merge_info['dn'] = group_info.progress_apply(lambda x: ta.volatility.bollinger_lband(close = x['수정종가'], window = 20, window_dev = 2)).reset_index(level = 0).iloc[:, -1]\n",
      "/tmp/ipykernel_431/975709587.py:82: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merge_info[cross_name] = 0\n",
      "/tmp/ipykernel_431/975709587.py:82: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merge_info[cross_name] = 0\n",
      "/tmp/ipykernel_431/975709587.py:82: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merge_info[cross_name] = 0\n",
      "/tmp/ipykernel_431/975709587.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merge_info['Bband_Cross'] = 0\n",
      "/tmp/ipykernel_431/975709587.py:107: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merge_info['_ts'] = os.environ['_ts']\n"
     ]
    }
   ],
   "source": [
    "# 이평선 관련\n",
    "group_info = merge_info.groupby('종목코드')\n",
    "for day in conf['agg_days']:\n",
    "    logger.info(f\"aggregating process of {day}days starts!\")\n",
    "    ## 종가\n",
    "    # 이평\n",
    "    merge_info[f'종가_이평{day}일'] = group_info['수정종가'].rolling(window=day).mean().reset_index(level = 0).iloc[:, -1]\n",
    "    # 괴리율\n",
    "    merge_info[f'종가_이평{day}일_괴리율'] = merge_info['수정종가'] / merge_info[f'종가_이평{day}일'] * 100\n",
    "\n",
    "    ## 거래량\n",
    "    # 이평\n",
    "    merge_info[f'거래량_이평{day}일'] = group_info['수정거래량'].rolling(window=day).mean().reset_index(level = 0).iloc[:, -1]\n",
    "    # 합\n",
    "    merge_info[f'거래량_합{day}일'] = group_info['수정거래량'].rolling(window=day).sum().reset_index(level = 0).iloc[:, -1]\n",
    "    \n",
    "    ## 시총이평\n",
    "    merge_info[f'시총_이평{day}일'] = group_info['시가총액'].rolling(window=day).mean().reset_index(level = 0).iloc[:, -1]\n",
    "    # 거래대금이평\n",
    "    merge_info[f'거래대금_이평{day}일'] = group_info['거래대금'].rolling(window=day).mean().reset_index(level = 0).iloc[:, -1]\n",
    "    # 거래대금 합\n",
    "    merge_info[f'거래대금_합{day}일'] = group_info['거래대금'].rolling(window=day).sum().reset_index(level = 0).iloc[:, -1]\n",
    "    \n",
    "    ## 수익률\n",
    "    # 이평\n",
    "    merge_info[f\"수익률{day}일\"] = group_info['수익률'].rolling(day).progress_apply(lambda x: ((1+x/100).prod() - 1) * 100, raw = True).reset_index(level = 0).iloc[:, -1]\n",
    "    # 시장대비\n",
    "    merge_info[f\"시장대비_수익률{day}일\"] = merge_info[f\"수익률{day}일\"] - merge_info[f\"시장수익률{day}일\"]\n",
    "    # 변동성\n",
    "    merge_info[f'수익률_변동성{day}일'] = group_info['수익률'].rolling(window=day).std().reset_index(level = 0).iloc[:, -1]\n",
    "    # 이평 연율화\n",
    "    merge_info[f'수익률{day}일_연율화'] = ((1 + merge_info[f\"수익률{day}일\"] / 100) ** (240 / 720) - 1) * 100\n",
    "    # 변동성 연율화\n",
    "    merge_info[f'수익률_변동성{day}일_연율화'] = merge_info[f'수익률_변동성{day}일'] / np.sqrt(240)\n",
    "    # sr 연율화\n",
    "    merge_info[f'SR_{day}일_연율화'] =  merge_info[f'수익률{day}일_연율화'] / merge_info[f'수익률_변동성{day}일_연율화']\n",
    "\n",
    "# n일 최고/최저가\n",
    "for day in conf['high_low_days']:\n",
    "    merge_info[f'최고가{day}일'] = group_info['수정고가'].rolling(window=day).max().reset_index(level = 0).iloc[:, -1]\n",
    "    merge_info[f'최저가{day}일'] = group_info['수정저가'].rolling(window=day).min().reset_index(level = 0).iloc[:, -1]\n",
    "    # 괴리율\n",
    "    merge_info[f'최고가{day}일_괴리율'] = merge_info['수정종가'] / merge_info[f'최고가{day}일'] * 100\n",
    "    merge_info[f'최저가{day}일_괴리율'] = merge_info['수정종가'] / merge_info[f'최저가{day}일'] * 100\n",
    "\n",
    "\n",
    "# 거래량\n",
    "merge_info[f'거래량1일_증가율'] = merge_info.apply(lambda x: np.nan if x['거래량_이평20일'] == 0 else x['수정거래량'] / x['거래량_이평20일'] * 100, axis = 1)\n",
    "merge_info[f'거래량5일_증가율'] = merge_info.apply(lambda x: np.nan if x['거래량_이평20일'] == 0 else x['거래량_이평5일'] / x['거래량_이평20일'] * 100, axis = 1)\n",
    "\n",
    "# 거래대금시총비율\n",
    "merge_info[f'거래대금시총비율_1일'] = merge_info[f'거래대금'] / merge_info[f'시가총액'] * 100\n",
    "merge_info[f'거래대금시총비율_5일'] = merge_info[f'거래대금_이평5일'] / merge_info[f'시총_이평5일'] * 100\n",
    "\n",
    "# 거래대금증가율\n",
    "merge_info['전일거래대금'] = group_info['거래대금'].shift(1)\n",
    "merge_info[f'거래대금_전일대비_증가율'] = merge_info.apply(lambda x: np.nan if x['전일거래대금'] == 0 else x['거래대금'] / x['전일거래대금'] * 100, axis = 1)\n",
    "merge_info[f'거래대금_5일이평대비_증가율'] = merge_info.apply(lambda x: np.nan if x['거래대금_이평5일'] == 0 else x['거래대금'] / x['거래대금_이평5일'] * 100, axis = 1)\n",
    "\n",
    "\n",
    "\n",
    "# 기술적 지표 생성\n",
    "merge_info['MACD'] = group_info.progress_apply(lambda x: ta.trend.macd(close = x['수정종가'], window_slow = 26, window_fast = 12)).reset_index(level = 0).iloc[:, -1]\n",
    "merge_info['MACD_signal'] = group_info.progress_apply(lambda x: ta.trend.macd_signal(close = x['수정종가'], window_slow = 26, window_fast = 12, window_sign = 9)).reset_index(level = 0).iloc[:, -1]\n",
    "merge_info['MACD_diff_signal'] = merge_info['MACD'] - merge_info['MACD_signal']\n",
    "merge_info['RSI'] = group_info.progress_apply(lambda x: ta.momentum.rsi(close = x['수정종가'], window = 14)).reset_index(level = 0).iloc[:, -1]\n",
    "\n",
    "# Stochastic\n",
    "merge_info['fastK'] = group_info.progress_apply(lambda x: ta.momentum.stoch(high = x['수정고가'], low = x['수정저가'], close = x['수정종가'], window=14, smooth_window=1)).reset_index(level = 0).iloc[:, -1]\n",
    "merge_info['fastD'] = merge_info.groupby('종목코드')['fastK'].rolling(window=3).mean().reset_index(level = 0).iloc[:, -1]\n",
    "merge_info['slowK'] = merge_info['fastD'].copy()\n",
    "merge_info['slowD'] = merge_info.groupby('종목코드')['slowK'].rolling(window=3).mean().reset_index(level = 0).iloc[:, -1]\n",
    "\n",
    "\n",
    "# 볼린저밴드\n",
    "merge_info['mavg'] = group_info.progress_apply(lambda x: ta.volatility.bollinger_mavg(close = x['수정종가'], window = 20)).reset_index(level = 0).iloc[:, -1]\n",
    "merge_info['up'] = group_info.progress_apply(lambda x: ta.volatility.bollinger_hband(close = x['수정종가'], window = 20, window_dev = 2)).reset_index(level = 0).iloc[:, -1]\n",
    "merge_info['dn'] = group_info.progress_apply(lambda x: ta.volatility.bollinger_lband(close = x['수정종가'], window = 20, window_dev = 2)).reset_index(level = 0).iloc[:, -1]\n",
    "\n",
    "# 골든 데드\n",
    "for cross_name, cross_cols in conf['tech_signal'].items():\n",
    "    merge_info[cross_name] = 0\n",
    "    left = merge_info.groupby('종목코드')[cross_cols[0]]\n",
    "    right = merge_info.groupby('종목코드')[cross_cols[1]]\n",
    "    merge_info.loc[(left.shift(1) <= right.shift(1)) & (left.shift(0) > right.shift(0)), cross_name] = 1 \n",
    "    merge_info.loc[(left.shift(1) >= right.shift(1)) & (left.shift(0) < right.shift(0)), cross_name] = -1\n",
    "    merge_info.loc[merge_info[cross_cols[0]].isnull() | merge_info[cross_cols[1]].isnull(), cross_name] = np.nan\n",
    "\n",
    "merge_info['Bband_Cross'] = 0\n",
    "left = merge_info.groupby('종목코드')['수정종가']\n",
    "right = merge_info.groupby('종목코드')['up']\n",
    "merge_info.loc[(left.shift(1) <= right.shift(1)) & (left.shift(0) > right.shift(0)) & (merge_info['up'] > merge_info['mavg'] * 1.15), 'Bband_Cross'] = 1\n",
    "right = merge_info.groupby('종목코드')['dn']\n",
    "merge_info.loc[(left.shift(1) >= right.shift(1)) & (left.shift(0) < right.shift(0)) & (merge_info['dn'] > merge_info['mavg'] * 1.15), 'Bband_Cross'] = -1\n",
    "merge_info.loc[merge_info['up'].isnull() | merge_info['dn'].isnull() | merge_info['mavg'].isnull(), 'Bband_Cross'] = np.nan\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 저장할 데이터 기간 filter\n",
    "if not full_save:\n",
    "    merge_info = pd.concat([merge_info.loc[merge_info['종목코드'].isin(full_save_stocks), :], \n",
    "                            merge_info[merge_info['기준일자'] >= upload_date]]).drop_duplicates(keep = 'first')\n",
    "\n",
    "# 그외 전처리\n",
    "merge_info['종목코드'] = 'A' + merge_info['종목코드']\n",
    "merge_info['_ts'] = os.environ['_ts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b2725fab-4071-43ae-b564-10205e5d03f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-21 23:23:29,118 (utils.py 326) INFO ::: df insert to db starts!, schema: stocks, table: daily_stock.\n",
      "2024-08-21 23:23:29,118 (utils.py 284) INFO ::: data processing is started!\n",
      "2024-08-21 23:23:29,118 (utils.py 396) INFO ::: sql execute: DESCRIBE TABLE stocks.daily_stock\n",
      "2024-08-22 00:03:45,167 (utils.py 396) INFO ::: sql execute: SELECT sorting_key FROM system.tables WHERE name = 'daily_stock' AND database = 'stocks'\n",
      "2024-08-22 00:03:45,175 (utils.py 305) INFO ::: data processing is finished.\n",
      "2024-08-22 00:04:45,863 (utils.py 337) INFO ::: data insert is processing (1000000/7211339).\n",
      "2024-08-22 00:05:45,953 (utils.py 337) INFO ::: data insert is processing (2000000/7211339).\n",
      "2024-08-22 00:06:46,067 (utils.py 337) INFO ::: data insert is processing (3000000/7211339).\n",
      "2024-08-22 00:07:45,664 (utils.py 337) INFO ::: data insert is processing (4000000/7211339).\n",
      "2024-08-22 00:08:45,655 (utils.py 337) INFO ::: data insert is processing (5000000/7211339).\n",
      "2024-08-22 00:09:45,437 (utils.py 337) INFO ::: data insert is processing (6000000/7211339).\n",
      "2024-08-22 00:10:42,872 (utils.py 337) INFO ::: data insert is processing (7000000/7211339).\n",
      "2024-08-22 00:10:55,113 (utils.py 337) INFO ::: data insert is processing (7211339/7211339).\n",
      "2024-08-22 00:10:55,114 (utils.py 339) INFO ::: data insert is finished.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7211339"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 업로드\n",
    "click_conn.df_insert(merge_info, conf['daily_stock']['database'], conf['daily_stock']['table'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
